{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Literate programming and interactive reporting with Jupyter notebooks Dashboard Workshop materials for the 2022 Data Science Research Bazaar at UW-Madison. This is an intermediate level workshop that will teach how to use Jupyter notebooks with Python for literate programming and interactive presentation of research results. I walk participants through steps of a mini research project of visualizing geospatial data, focusing on tools and methods of making results accessible, reproducible and interactive. This workshop will use economic, demographic and geographic data characterizing US communities that are freely and publicly available from the US Census Bureau website. Prior programming and data analysis experience is recommended for full participation in the workshop. If you are new to Python, I recommend reading about Jupyter and pandas . This book shows how to use Jupyter notebooks for teaching and learning, and QuantEcon lectures use Python for economics and finance and are also a good resource for beginners. Workshop topics: - Jupyter notebooks and Markdown - code organization, Python modules and packages, conversion to scripts - static documentation, conversion to HTML - data retrieval via download and API - data processing and analysis in pandas - plotting with matplotlib - building interactive interfaces with notebook widgets - visualization of geospatial data, geopandas and ipyleaflet - hosting live notebooks and Voil\u00e0 dashboards on Binder Setup You need a running Jupyter server in order to work with workshop notebooks. The easiest way is to launch a free cloud instance in Binder . A more difficult (but potentially more reliable) alternative is to create conda Python environment on your local computer. Using Binder Click this link to launch a new Binder instance and connect to it from your browser, then open and run the init notebook to test the environment and initialize paths. Ideal launch time is under 30 seconds, but it might take longer if the repository has been recently updated, because Binder will need to rebuild the environment from scratch. Notice that Binder platform provides computational resources for free, and so limitations are in place and availability can not be guaranteed. Read here about usage policy and available resources. Also static HTML documentation site will not be available. Local Python This method requires some experience or readiness to read documentation. As reward, you will have persistent environment under your control that does not depend on cloud service availability. This is also a typical way to set up Python for data work. Download and install latest miniconda , following instructions for your operating system. Open terminal (Anaconda Prompt on Windows) and clone this repository in a folder of your choice ( git clone https://github.com/antonbabkin/workshop-notebooks.git ). Alternatively, download and unpack repository code as ZIP. If you want to practice building and hosting HTML documentation, you need to use a repository that you control. One way to do it is to fork this repository and then clone your copy. In the terminal, navigate to the repository folder and create new conda environment . Environment specification will be read from the environment.yml file, all required packages will be downloaded and installed. cd workshop-notebooks conda env create Activate the environment and start JupyterLab server. This will start a new Jupyter server and open Jupyter interface in browser window. conda activate workshop-nbs-2022 jupyter lab In Jupyter, open and run the init notebook to test the environment and initialize paths. License Project code is licensed under the MIT license . All other content is licensed under the Creative Commons Attribution 4.0 International license .","title":"Home"},{"location":"#literate-programming-and-interactive-reporting-with-jupyter-notebooks","text":"Dashboard Workshop materials for the 2022 Data Science Research Bazaar at UW-Madison. This is an intermediate level workshop that will teach how to use Jupyter notebooks with Python for literate programming and interactive presentation of research results. I walk participants through steps of a mini research project of visualizing geospatial data, focusing on tools and methods of making results accessible, reproducible and interactive. This workshop will use economic, demographic and geographic data characterizing US communities that are freely and publicly available from the US Census Bureau website. Prior programming and data analysis experience is recommended for full participation in the workshop. If you are new to Python, I recommend reading about Jupyter and pandas . This book shows how to use Jupyter notebooks for teaching and learning, and QuantEcon lectures use Python for economics and finance and are also a good resource for beginners. Workshop topics: - Jupyter notebooks and Markdown - code organization, Python modules and packages, conversion to scripts - static documentation, conversion to HTML - data retrieval via download and API - data processing and analysis in pandas - plotting with matplotlib - building interactive interfaces with notebook widgets - visualization of geospatial data, geopandas and ipyleaflet - hosting live notebooks and Voil\u00e0 dashboards on Binder","title":"Literate programming and interactive reporting with Jupyter notebooks"},{"location":"#setup","text":"You need a running Jupyter server in order to work with workshop notebooks. The easiest way is to launch a free cloud instance in Binder . A more difficult (but potentially more reliable) alternative is to create conda Python environment on your local computer.","title":"Setup"},{"location":"#using-binder","text":"Click this link to launch a new Binder instance and connect to it from your browser, then open and run the init notebook to test the environment and initialize paths. Ideal launch time is under 30 seconds, but it might take longer if the repository has been recently updated, because Binder will need to rebuild the environment from scratch. Notice that Binder platform provides computational resources for free, and so limitations are in place and availability can not be guaranteed. Read here about usage policy and available resources. Also static HTML documentation site will not be available.","title":"Using Binder"},{"location":"#local-python","text":"This method requires some experience or readiness to read documentation. As reward, you will have persistent environment under your control that does not depend on cloud service availability. This is also a typical way to set up Python for data work. Download and install latest miniconda , following instructions for your operating system. Open terminal (Anaconda Prompt on Windows) and clone this repository in a folder of your choice ( git clone https://github.com/antonbabkin/workshop-notebooks.git ). Alternatively, download and unpack repository code as ZIP. If you want to practice building and hosting HTML documentation, you need to use a repository that you control. One way to do it is to fork this repository and then clone your copy. In the terminal, navigate to the repository folder and create new conda environment . Environment specification will be read from the environment.yml file, all required packages will be downloaded and installed. cd workshop-notebooks conda env create Activate the environment and start JupyterLab server. This will start a new Jupyter server and open Jupyter interface in browser window. conda activate workshop-nbs-2022 jupyter lab In Jupyter, open and run the init notebook to test the environment and initialize paths.","title":"Local Python"},{"location":"#license","text":"Project code is licensed under the MIT license . All other content is licensed under the Creative Commons Attribution 4.0 International license .","title":"License"},{"location":"analysis/","text":"Analysis of population and employment dynamics DF['by year'] = data_by_year() DF['by year'].head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } st cty year pop pop_gr emp emp_gr 0 00 000 1990 249470539 NaN 93983875.0 2.145 1 00 000 1991 252208537 1.097524 91781210.0 -2.439 2 00 000 1992 255104027 1.148054 91752935.0 0.004 3 00 000 1993 257857622 1.079401 93252746.0 1.560 4 00 000 1994 260401091 0.986385 95712240.0 2.254 plot_growth('55', '025', 2005, 2015) Compare different areas Average growth rate of variable x_t between years s and t is computed as x_{agr} = \\left(\\frac{x_t}{x_s}\\right)^{\\frac{1}{t-s+1}} . d = compute_agr(2000, 2010) d['c'] = color_from_agr_cat(d, 'abs') d.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } st cty emp_agr_abs pop_agr_abs ref_emp_agr ref_pop_agr pop_agr_rel emp_agr_rel agr_cat_abs agr_cat_rel c 0 00 000 -0.173731 0.838944 -0.173731 0.838944 0.000000 0.000000 pop+ emp- pop+ emp+ green 1 01 000 -0.497312 0.658386 -0.173731 0.838944 -0.180558 -0.323581 pop+ emp- pop- emp- green 2 01 001 0.546082 2.006507 -0.497312 0.658386 1.348121 1.043393 pop+ emp+ pop+ emp+ red 3 01 003 0.865040 2.381697 -0.497312 0.658386 1.723312 1.362352 pop+ emp+ pop+ emp+ red 4 01 005 -3.554504 -0.543406 -0.497312 0.658386 -1.201792 -3.057192 pop- emp- pop- emp- blue plot_agr('55', 2005, 2015, 'rel')","title":"Analysis"},{"location":"analysis/#analysis-of-population-and-employment-dynamics","text":"DF['by year'] = data_by_year() DF['by year'].head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } st cty year pop pop_gr emp emp_gr 0 00 000 1990 249470539 NaN 93983875.0 2.145 1 00 000 1991 252208537 1.097524 91781210.0 -2.439 2 00 000 1992 255104027 1.148054 91752935.0 0.004 3 00 000 1993 257857622 1.079401 93252746.0 1.560 4 00 000 1994 260401091 0.986385 95712240.0 2.254 plot_growth('55', '025', 2005, 2015)","title":"Analysis of population and employment dynamics"},{"location":"analysis/#compare-different-areas","text":"Average growth rate of variable x_t between years s and t is computed as x_{agr} = \\left(\\frac{x_t}{x_s}\\right)^{\\frac{1}{t-s+1}} . d = compute_agr(2000, 2010) d['c'] = color_from_agr_cat(d, 'abs') d.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } st cty emp_agr_abs pop_agr_abs ref_emp_agr ref_pop_agr pop_agr_rel emp_agr_rel agr_cat_abs agr_cat_rel c 0 00 000 -0.173731 0.838944 -0.173731 0.838944 0.000000 0.000000 pop+ emp- pop+ emp+ green 1 01 000 -0.497312 0.658386 -0.173731 0.838944 -0.180558 -0.323581 pop+ emp- pop- emp- green 2 01 001 0.546082 2.006507 -0.497312 0.658386 1.348121 1.043393 pop+ emp+ pop+ emp+ red 3 01 003 0.865040 2.381697 -0.497312 0.658386 1.723312 1.362352 pop+ emp+ pop+ emp+ red 4 01 005 -3.554504 -0.543406 -0.497312 0.658386 -1.201792 -3.057192 pop- emp- pop- emp- blue plot_agr('55', 2005, 2015, 'rel')","title":"Compare different areas"},{"location":"data/","text":"Retrieve and prepare data Geography geocodes geo().head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } st cty name geometry 0 01 000 Alabama POLYGON ((-88.46866 31.89386, -88.46866 31.933... 1 01 001 Autauga county, Alabama POLYGON ((-86.91759 32.66417, -86.71339 32.661... 2 01 003 Baldwin county, Alabama POLYGON ((-88.02632 30.75336, -87.94455 30.827... 3 01 005 Barbour county, Alabama POLYGON ((-85.73573 31.62449, -85.66565 31.786... 4 01 007 Bibb county, Alabama POLYGON ((-87.42194 33.00338, -87.31854 33.006... Population home 2000-2010 2010-2019 For years before 1990 I could not find data in convenient format. Character encoding : newer files use \"UTF-8\", older use \"ISO-8859-1\". pop().head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } st cty year pop pop_gr 95790 00 000 1990 249470539 NaN 95791 00 000 1991 252208537 1.097524 95792 00 000 1992 255104027 1.148054 95793 00 000 1993 257857622 1.079401 95794 00 000 1994 260401091 0.986385 Employment datasets emp().head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } st cty year emp emp_gr 0 00 000 1978 69410001.0 7.778 1 00 000 1979 73848234.0 5.923 2 00 000 1980 74109267.0 0.255 3 00 000 1981 75728652.0 2.148 4 00 000 1982 74922226.0 -0.901 API BDS API import requests key = open(nbd.root/'census_api_key.txt').read() url = 'https://api.census.gov/data/timeseries/bds' st = '55' r = requests.get(f'{url}?get=NAME,ESTAB,EMP,YEAR&for=county:*&in=state:{st}&time=from+2015+to+2019&NAICS=00&key={key}') d = r.json() df = pd.DataFrame(d[1:], columns=d[0]) df.query('county == \"025\"').head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } NAME ESTAB EMP YEAR time NAICS state county 237 Dane County, Wisconsin 12649 269895 2015 2015 00 55 025 238 Dane County, Wisconsin 12974 275642 2016 2016 00 55 025 239 Dane County, Wisconsin 13047 280403 2017 2017 00 55 025 240 Dane County, Wisconsin 13088 297744 2018 2018 00 55 025 241 Dane County, Wisconsin 13099 301777 2019 2019 00 55 025","title":"Data"},{"location":"data/#retrieve-and-prepare-data","text":"","title":"Retrieve and prepare data"},{"location":"data/#geography","text":"geocodes geo().head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } st cty name geometry 0 01 000 Alabama POLYGON ((-88.46866 31.89386, -88.46866 31.933... 1 01 001 Autauga county, Alabama POLYGON ((-86.91759 32.66417, -86.71339 32.661... 2 01 003 Baldwin county, Alabama POLYGON ((-88.02632 30.75336, -87.94455 30.827... 3 01 005 Barbour county, Alabama POLYGON ((-85.73573 31.62449, -85.66565 31.786... 4 01 007 Bibb county, Alabama POLYGON ((-87.42194 33.00338, -87.31854 33.006...","title":"Geography"},{"location":"data/#population","text":"home 2000-2010 2010-2019 For years before 1990 I could not find data in convenient format. Character encoding : newer files use \"UTF-8\", older use \"ISO-8859-1\". pop().head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } st cty year pop pop_gr 95790 00 000 1990 249470539 NaN 95791 00 000 1991 252208537 1.097524 95792 00 000 1992 255104027 1.148054 95793 00 000 1993 257857622 1.079401 95794 00 000 1994 260401091 0.986385","title":"Population"},{"location":"data/#employment","text":"datasets emp().head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } st cty year emp emp_gr 0 00 000 1978 69410001.0 7.778 1 00 000 1979 73848234.0 5.923 2 00 000 1980 74109267.0 0.255 3 00 000 1981 75728652.0 2.148 4 00 000 1982 74922226.0 -0.901","title":"Employment"},{"location":"data/#api","text":"BDS API import requests key = open(nbd.root/'census_api_key.txt').read() url = 'https://api.census.gov/data/timeseries/bds' st = '55' r = requests.get(f'{url}?get=NAME,ESTAB,EMP,YEAR&for=county:*&in=state:{st}&time=from+2015+to+2019&NAICS=00&key={key}') d = r.json() df = pd.DataFrame(d[1:], columns=d[0]) df.query('county == \"025\"').head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } NAME ESTAB EMP YEAR time NAICS state county 237 Dane County, Wisconsin 12649 269895 2015 2015 00 55 025 238 Dane County, Wisconsin 12974 275642 2016 2016 00 55 025 239 Dane County, Wisconsin 13047 280403 2017 2017 00 55 025 240 Dane County, Wisconsin 13088 297744 2018 2018 00 55 025 241 Dane County, Wisconsin 13099 301777 2019 2019 00 55 025","title":"API"},{"location":"tools/","text":"Tools and utilities NBD: development in the notebook turn notebooks into importable Python package documentation MkDocs File download Example usage: download LICENSE file from GitHub repo and assert that it's contents is the same as in the local repo version. nbd = Nbd('popemp') f = download_file('https://raw.githubusercontent.com/antonbabkin/workshop-notebooks/main/LICENSE', nbd.root, 'LICENSE_COPY') assert open(nbd.root/'LICENSE').read() == open(f).read() f.unlink() Download complete: LICENSE_COPY. Build this module This notebook itself is turned into importable module by running the code below. nbd = Nbd('popemp') nbd.nb2mod('tools.ipynb') Converted notebook \"nbs/tools.ipynb\" to module \"popemp/tools.py\".","title":"Tools"},{"location":"tools/#tools-and-utilities","text":"","title":"Tools and utilities"},{"location":"tools/#nbd-development-in-the-notebook","text":"","title":"NBD: development in the notebook"},{"location":"tools/#turn-notebooks-into-importable-python-package","text":"","title":"turn notebooks into importable Python package"},{"location":"tools/#documentation","text":"MkDocs","title":"documentation"},{"location":"tools/#file-download","text":"Example usage: download LICENSE file from GitHub repo and assert that it's contents is the same as in the local repo version. nbd = Nbd('popemp') f = download_file('https://raw.githubusercontent.com/antonbabkin/workshop-notebooks/main/LICENSE', nbd.root, 'LICENSE_COPY') assert open(nbd.root/'LICENSE').read() == open(f).read() f.unlink() Download complete: LICENSE_COPY.","title":"File download"},{"location":"tools/#build-this-module","text":"This notebook itself is turned into importable module by running the code below. nbd = Nbd('popemp') nbd.nb2mod('tools.ipynb') Converted notebook \"nbs/tools.ipynb\" to module \"popemp/tools.py\".","title":"Build this module"}]}